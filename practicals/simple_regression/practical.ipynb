{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the notebook reloads the module each time we modify it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make sure the displays are nice\n",
    "%matplotlib inline\n",
    "#figsize(12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simple_regression as sr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "import numpy as np\n",
    "import numpy.linalg as npl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prepared a class that fetches data for you\n",
    "PM = sr.PracticalMaterial()\n",
    "X, y = PM.fetch_data()\n",
    "\n",
    "# Let us plot data\n",
    "sns.scatterplot(X, y)\n",
    "print(\"Problem dimensions are\", X.shape)\n",
    "plt.ylabel(\"log GDP\")\n",
    "plt.xlabel(\"Ruggedness indes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you work for a geographer. She wants to test the hypothesis that the log GDP increases with ruggedness. You reply that without knowledge about how $X$ and $y$ relate, and only 170 points, it seems reasonable to stick to a simple model, say linear regression. \n",
    "\n",
    "**Question:** Assuming you perform a linear regression of the log GDP onto the ruggedness index, how will you formalize the test that the geographer is asking for? What quantity do you want to report?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** First write down your model (likelihood and prior), and find the MAP to get an idea what to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_map, inverse_hessian = PM.find_map()\n",
    "print(theta_map, np.diag(inverse_hessian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(X, y)\n",
    "plt.ylabel(\"log GDP\")\n",
    "plt.xlabel(\"Ruggedness indes\")\n",
    "plt.plot(X, theta_map[0] + theta_map[1]*X, label=\"map\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** we haven't performed Bayesian inference yet, but do you interpret the MAP as evidence for a yes or a no?\n",
    "\n",
    "**Question:** perform a Laplace approximation to the posterior, what would you then answer to the geographer? *Hint: we have already computed everything for the Laplace approximation, so answering this question should require no coding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance sampling\n",
    "The number of parameters is $3$, this is low enough that we can hope importance sampling to yield small variance. We are first going to implement a generic class for self-normalized importance sampling, with a target given by its log.\n",
    "\n",
    "**Question:** Fill out the methods of the `ImportanceSampling` class, and test it on a few integrals for which you know a closed form. For instance, find one integral that is easy for IS with a Gaussian proposal, and one that is hard. Then change the proposal to try to make your hard integral more tractable. \n",
    "\n",
    "**Question:** In all cases, compute the essential sample size and try to see if it is a useful diagnostic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring the linear regression parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now we turn to inferring the parameters, how big can you make the ESS by tuning the proposal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS = sr.ImportanceSampling(dimension=3, log_target=PM.get_log_target, \n",
    "                           num_samples=1000)\n",
    "IS.find_map(verbose=True)\n",
    "IS.propose()\n",
    "res = IS.get_estimate(lambda theta:theta)\n",
    "print(\"theta_MEP is\", res, \"and ESS per sample is\", IS.get_ess_per_sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** And now, what do we answer our geographer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Now the geographer tells you that she is twice more sensitive to announcing that GDP increases with ruggedness while it doesn't, than the contrary. Does that change your decision? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
